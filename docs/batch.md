# æ‰¹é‡å¤„ç†

## æ¦‚è¿°

æ‰¹é‡å¤„ç†åŠŸèƒ½å…è®¸æ‚¨åŒæ—¶å¯¼å‡ºå¤šæœ¬ä¹¦ç±ï¼Œå¤§å¤§æé«˜å·¥ä½œæ•ˆç‡ã€‚æœ¬ç« å°†è¯¦ç»†ä»‹ç»æ‰¹é‡å¯¼å‡ºçš„å„ç§æ–¹æ³•å’Œæœ€ä½³å®è·µã€‚

## åŸºæœ¬æ‰¹é‡å¯¼å‡º

### 1. å‘½ä»¤è¡Œæ‰¹é‡å¯¼å‡º

#### ä»æ–‡ä»¶æ‰¹é‡å¯¼å‡º

åˆ›å»ºåŒ…å«ä¹¦ç±IDçš„æ–‡æœ¬æ–‡ä»¶ï¼š

```bash
# åˆ›å»ºä¹¦ç±IDåˆ—è¡¨æ–‡ä»¶
cat > books.txt << EOF
08232ac0720befa90825d88
1a2b3c4d5e6f7g8h9i0j1k
book_id_3_here
book_id_4_here
EOF

# æ‰¹é‡å¯¼å‡º
weread-exporter --batch books.txt -o epub -o pdf
```

#### ç›´æ¥æŒ‡å®šå¤šä¸ªID

```bash
# ç›´æ¥åœ¨å‘½ä»¤è¡ŒæŒ‡å®šå¤šä¸ªä¹¦ç±ID
weread-exporter --book-ids "id1,id2,id3" -o epub

# æˆ–ä½¿ç”¨ç©ºæ ¼åˆ†éš”
weread-exporter --book-ids "id1 id2 id3" -o epub
```

### 2. æ‰¹é‡å¯¼å‡ºå‚æ•°

```bash
# åŸºæœ¬æ‰¹é‡å¯¼å‡º
weread-exporter --batch books.txt -o epub

# æŒ‡å®šè¾“å‡ºç›®å½•
weread-exporter --batch books.txt -o epub --output-dir ~/batch_books

# è®¾ç½®å¹¶å‘æ•°é‡
weread-exporter --batch books.txt -o epub --concurrency 3

# æ— å¤´æ¨¡å¼ï¼ˆæ¨èç”¨äºæ‰¹é‡ï¼‰
weread-exporter --batch books.txt -o epub --headless
```

## é«˜çº§æ‰¹é‡é…ç½®

### 1. å¹¶å‘æ§åˆ¶

```bash
# é™åˆ¶å¹¶å‘æ•°é‡ï¼ˆé¿å…è¢«å°ï¼‰
weread-exporter --batch books.txt -o epub --concurrency 2

# åŠ¨æ€å¹¶å‘æ§åˆ¶
weread-exporter --batch books.txt -o epub --adaptive-concurrency

# è®¾ç½®è¯·æ±‚é—´éš”
weread-exporter --batch books.txt -o epub --request-interval 5
```

### 2. é”™è¯¯å¤„ç†

```bash
# è·³è¿‡é”™è¯¯ç»§ç»­å¤„ç†
weread-exporter --batch books.txt -o epub --skip-errors

# å¤±è´¥é‡è¯•æ¬¡æ•°
weread-exporter --batch books.txt -o epub --max-retries 3

# ä¿å­˜å¤±è´¥åˆ—è¡¨
weread-exporter --batch books.txt -o epub --save-failures failed.txt

# ä»…é‡è¯•å¤±è´¥çš„ä¹¦ç±
weread-exporter --retry-failed failed.txt -o epub
```

### 3. è¿›åº¦ç›‘æ§

```bash
# æ˜¾ç¤ºè¯¦ç»†è¿›åº¦
weread-exporter --batch books.txt -o epub --verbose

# è¿›åº¦æ¡æ˜¾ç¤º
weread-exporter --batch books.txt -o epub --progress

# å®æ—¶ç»Ÿè®¡ä¿¡æ¯
weread-exporter --batch books.txt -o epub --stats

# ç”Ÿæˆè¿›åº¦æŠ¥å‘Š
weread-exporter --batch books.txt -o epub --progress-report report.json
```

## æ‰¹é‡å¤„ç†è„šæœ¬

### 1. åŸºç¡€æ‰¹é‡è„šæœ¬

```bash
#!/bin/bash
# batch_export.sh

BOOKS_FILE="books.txt"
OUTPUT_DIR="~/batch_output"
FORMATS="epub pdf"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "$OUTPUT_DIR"

# æ‰¹é‡å¯¼å‡º
while IFS= read -r book_id; do
    if [[ -n "$book_id" ]]; then
        echo "æ­£åœ¨å¯¼å‡º: $book_id"
        weread-exporter -b "$book_id" -o $FORMATS --headless --output-dir "$OUTPUT_DIR"
        echo "å¯¼å‡ºå®Œæˆ: $book_id"
        echo "---"
    fi
done < "$BOOKS_FILE"

echo "æ‰¹é‡å¯¼å‡ºå®Œæˆ!"
```

### 2. é«˜çº§æ‰¹é‡è„šæœ¬

```bash
#!/bin/bash
# advanced_batch.sh

BOOKS_FILE="${1:-books.txt}"
OUTPUT_DIR="${2:-~/batch_books}"
LOG_FILE="batch_export.log"
FAILED_FILE="failed_books.txt"

# åˆå§‹åŒ–
mkdir -p "$OUTPUT_DIR"
rm -f "$FAILED_FILE"

echo "å¼€å§‹æ‰¹é‡å¯¼å‡º $(date)" | tee -a "$LOG_FILE"

SUCCESS=0
FAILED=0
TOTAL=$(wc -l < "$BOOKS_FILE")

# å¤„ç†æ¯æœ¬ä¹¦ç±
while IFS= read -r book_id; do
    if [[ -n "$book_id" ]]; then
        echo "[$((SUCCESS + FAILED + 1))/$TOTAL] å¤„ç†: $book_id" | tee -a "$LOG_FILE"
        
        if weread-exporter -b "$book_id" -o epub pdf --headless --output-dir "$OUTPUT_DIR" 2>> "$LOG_FILE"; then
            echo "âœ… æˆåŠŸ: $book_id" | tee -a "$LOG_FILE"
            ((SUCCESS++))
        else
            echo "âŒ å¤±è´¥: $book_id" | tee -a "$LOG_FILE"
            echo "$book_id" >> "$FAILED_FILE"
            ((FAILED++))
        fi
        
        # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        sleep 2
    fi
done < "$BOOKS_FILE"

# ç”ŸæˆæŠ¥å‘Š
echo "=== æ‰¹é‡å¯¼å‡ºæŠ¥å‘Š ===" | tee -a "$LOG_FILE"
echo "å®Œæˆæ—¶é—´: $(date)" | tee -a "$LOG_FILE"
echo "æ€»è®¡: $TOTAL" | tee -a "$LOG_FILE"
echo "æˆåŠŸ: $SUCCESS" | tee -a "$LOG_FILE"
echo "å¤±è´¥: $FAILED" | tee -a "$LOG_FILE"

if [[ $FAILED -gt 0 ]]; then
    echo "å¤±è´¥ä¹¦ç±åˆ—è¡¨å·²ä¿å­˜åˆ°: $FAILED_FILE" | tee -a "$LOG_FILE"
fi
```

### 3. Pythonæ‰¹é‡è„šæœ¬

```python
#!/usr/bin/env python3
# batch_export.py

import asyncio
import sys
from pathlib import Path
from weread_exporter import WeReadExporter

class BatchExporter:
    def __init__(self, output_dir: str, max_concurrent: int = 3):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def export_book(self, book_id: str) -> dict:
        """å¯¼å‡ºå•æœ¬ä¹¦ç±"""
        async with self.semaphore:
            try:
                exporter = WeReadExporter(book_id, {
                    'output_dir': str(self.output_dir / book_id),
                    'headless': True,
                    'timeout': 120
                })
                
                result = await exporter.export(['epub', 'pdf'])
                return {'book_id': book_id, 'success': True, 'result': result}
                
            except Exception as e:
                return {'book_id': book_id, 'success': False, 'error': str(e)}
    
    async def export_batch(self, book_ids: list) -> dict:
        """æ‰¹é‡å¯¼å‡ºä¹¦ç±"""
        tasks = [self.export_book(book_id) for book_id in book_ids]
        results = await asyncio.gather(*tasks)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r['success'])
        failed_count = len(results) - success_count
        
        return {
            'total': len(results),
            'success': success_count,
            'failed': failed_count,
            'results': results
        }

async def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python batch_export.py <ä¹¦ç±IDæ–‡ä»¶>")
        sys.exit(1)
    
    books_file = sys.argv[1]
    
    # è¯»å–ä¹¦ç±ID
    with open(books_file, 'r') as f:
        book_ids = [line.strip() for line in f if line.strip()]
    
    print(f"æ‰¾åˆ° {len(book_ids)} æœ¬ä¹¦ç±")
    
    # æ‰¹é‡å¯¼å‡º
    exporter = BatchExporter('batch_output', max_concurrent=3)
    result = await exporter.export_batch(book_ids)
    
    # è¾“å‡ºç»“æœ
    print(f"\næ‰¹é‡å¯¼å‡ºå®Œæˆ:")
    print(f"æ€»è®¡: {result['total']}")
    print(f"æˆåŠŸ: {result['success']}")
    print(f"å¤±è´¥: {result['failed']}")
    
    # è¾“å‡ºå¤±è´¥è¯¦æƒ…
    if result['failed'] > 0:
        print("\nå¤±è´¥çš„ä¹¦ç±:")
        for r in result['results']:
            if not r['success']:
                print(f"  {r['book_id']}: {r['error']}")

if __name__ == "__main__":
    asyncio.run(main())
```

## æ‰¹é‡å¤„ç†ç­–ç•¥

### 1. å¹¶å‘ç­–ç•¥

#### å›ºå®šå¹¶å‘

```python
# å›ºå®šå¹¶å‘æ•°é‡
class FixedConcurrencyStrategy:
    def __init__(self, concurrency: int):
        self.concurrency = concurrency
    
    async def process_batch(self, items, process_func):
        semaphore = asyncio.Semaphore(self.concurrency)
        
        async def process_item(item):
            async with semaphore:
                return await process_func(item)
        
        tasks = [process_item(item) for item in items]
        return await asyncio.gather(*tasks)
```

#### åŠ¨æ€å¹¶å‘

```python
# åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°é‡
class AdaptiveConcurrencyStrategy:
    def __init__(self, initial_concurrency: int = 3, max_concurrency: int = 10):
        self.current_concurrency = initial_concurrency
        self.max_concurrency = max_concurrency
        self.success_rate = 1.0
    
    async def adjust_concurrency(self, success: bool):
        """æ ¹æ®æˆåŠŸç‡è°ƒæ•´å¹¶å‘æ•°é‡"""
        if success:
            self.success_rate = min(1.0, self.success_rate + 0.1)
            if self.success_rate > 0.9 and self.current_concurrency < self.max_concurrency:
                self.current_concurrency += 1
        else:
            self.success_rate = max(0.0, self.success_rate - 0.2)
            if self.success_rate < 0.7 and self.current_concurrency > 1:
                self.current_concurrency -= 1
```

### 2. é”™è¯¯å¤„ç†ç­–ç•¥

#### ç«‹å³é‡è¯•

```python
class ImmediateRetryStrategy:
    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
    
    async def execute_with_retry(self, coro, *args):
        for attempt in range(self.max_retries + 1):
            try:
                return await coro(*args)
            except Exception as e:
                if attempt == self.max_retries:
                    raise e
                print(f"å°è¯• {attempt + 1} å¤±è´¥ï¼Œç«‹å³é‡è¯•...")
```

#### æŒ‡æ•°é€€é¿

```python
class ExponentialBackoffStrategy:
    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
    
    async def execute_with_retry(self, coro, *args):
        for attempt in range(self.max_retries + 1):
            try:
                return await coro(*args)
            except Exception as e:
                if attempt == self.max_retries:
                    raise e
                
                delay = self.base_delay * (2 ** attempt)
                print(f"å°è¯• {attempt + 1} å¤±è´¥ï¼Œç­‰å¾… {delay} ç§’åé‡è¯•...")
                await asyncio.sleep(delay)
```

## æ‰¹é‡å¯¼å‡ºå·¥ä½œæµ

### 1. é¢„å¤„ç†é˜¶æ®µ

```python
async def preprocess_batch(book_ids: list) -> dict:
    """æ‰¹é‡é¢„å¤„ç†"""
    
    # éªŒè¯ä¹¦ç±IDæ ¼å¼
    valid_ids = []
    invalid_ids = []
    
    for book_id in book_ids:
        if validate_book_id(book_id):
            valid_ids.append(book_id)
        else:
            invalid_ids.append(book_id)
    
    # æ£€æŸ¥ä¹¦ç±å¯è®¿é—®æ€§
    accessible_ids = []
    inaccessible_ids = []
    
    for book_id in valid_ids:
        if await check_book_accessibility(book_id):
            accessible_ids.append(book_id)
        else:
            inaccessible_ids.append(book_id)
    
    return {
        'valid': valid_ids,
        'invalid': invalid_ids,
        'accessible': accessible_ids,
        'inaccessible': inaccessible_ids
    }
```

### 2. å¯¼å‡ºé˜¶æ®µ

```python
async def export_batch_phase(book_ids: list, strategy: BatchStrategy) -> dict:
    """æ‰¹é‡å¯¼å‡ºé˜¶æ®µ"""
    
    results = {}
    
    # å¹¶å‘å¯¼å‡º
    export_results = await strategy.execute_batch(
        book_ids, 
        export_single_book
    )
    
    # åˆ†ç±»ç»“æœ
    for book_id, result in zip(book_ids, export_results):
        if result['success']:
            results[book_id] = {
                'status': 'success',
                'files': result['output_files'],
                'size': result['total_size']
            }
        else:
            results[book_id] = {
                'status': 'failed',
                'error': result['error']
            }
    
    return results
```

### 3. åå¤„ç†é˜¶æ®µ

```python
async def postprocess_batch(export_results: dict) -> dict:
    """æ‰¹é‡åå¤„ç†"""
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    stats = {
        'total': len(export_results),
        'success': sum(1 for r in export_results.values() if r['status'] == 'success'),
        'failed': sum(1 for r in export_results.values() if r['status'] == 'failed'),
        'total_size': 0
    }
    
    # è®¡ç®—æ€»æ–‡ä»¶å¤§å°
    for result in export_results.values():
        if result['status'] == 'success':
            stats['total_size'] += result.get('size', 0)
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report = {
        'timestamp': datetime.now().isoformat(),
        'statistics': stats,
        'details': export_results
    }
    
    # ä¿å­˜æŠ¥å‘Š
    with open('batch_report.json', 'w') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    return report
```

## æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ä¼˜åŒ–

```python
class MemoryOptimizedBatchExporter:
    def __init__(self, memory_limit_mb: int = 512):
        self.memory_limit = memory_limit_mb * 1024 * 1024
        self.batch_size = self.calculate_optimal_batch_size()
    
    def calculate_optimal_batch_size(self) -> int:
        """æ ¹æ®å†…å­˜é™åˆ¶è®¡ç®—æœ€ä¼˜æ‰¹é‡å¤§å°"""
        # ä¼°ç®—å•æœ¬ä¹¦ç±çš„å†…å­˜ä½¿ç”¨
        estimated_memory_per_book = 50 * 1024 * 1024  # 50MB
        
        optimal_size = max(1, self.memory_limit // estimated_memory_per_book)
        return min(optimal_size, 10)  # æœ€å¤§æ‰¹é‡å¤§å°é™åˆ¶
    
    async def export_large_batch(self, book_ids: list) -> dict:
        """åˆ†æ‰¹å¤„ç†å¤§æ‰¹é‡ä¹¦ç±"""
        
        all_results = {}
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(book_ids), self.batch_size):
            batch = book_ids[i:i + self.batch_size]
            
            print(f"å¤„ç†æ‰¹æ¬¡ {i//self.batch_size + 1}/{(len(book_ids)-1)//self.batch_size + 1}")
            
            # å¯¼å‡ºå½“å‰æ‰¹æ¬¡
            batch_results = await self.export_batch(batch)
            all_results.update(batch_results)
            
            # æ¸…ç†å†…å­˜
            await self.cleanup_memory()
        
        return all_results
```

### 2. ç½‘ç»œä¼˜åŒ–

```python
class NetworkOptimizedBatchExporter:
    def __init__(self, max_requests_per_minute: int = 60):
        self.rate_limiter = RateLimiter(max_requests_per_minute)
    
    async def export_with_rate_limit(self, book_ids: list) -> dict:
        """å¸¦é€Ÿç‡é™åˆ¶çš„æ‰¹é‡å¯¼å‡º"""
        
        results = {}
        
        for book_id in book_ids:
            # ç­‰å¾…é€Ÿç‡é™åˆ¶
            await self.rate_limiter.wait_if_needed()
            
            try:
                result = await self.export_single_book(book_id)
                results[book_id] = result
                
                # æ›´æ–°æˆåŠŸç‡ç»Ÿè®¡
                self.rate_limiter.record_success()
                
            except Exception as e:
                results[book_id] = {'error': str(e)}
                
                # æ›´æ–°å¤±è´¥ç‡ç»Ÿè®¡
                self.rate_limiter.record_failure()
        
        return results
```

## ç›‘æ§å’ŒæŠ¥å‘Š

### 1. å®æ—¶ç›‘æ§

```python
class BatchMonitor:
    def __init__(self, total_items: int):
        self.total = total_items
        self.completed = 0
        self.start_time = time.time()
        self.success_count = 0
        self.failure_count = 0
    
    def update_progress(self, success: bool = True):
        """æ›´æ–°è¿›åº¦"""
        self.completed += 1
        
        if success:
            self.success_count += 1
        else:
            self.failure_count += 1
        
        self.display_progress()
    
    def display_progress(self):
        """æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
        percentage = (self.completed / self.total) * 100
        elapsed = time.time() - self.start_time
        
        if self.completed > 0:
            estimated_total = elapsed * self.total / self.completed
            remaining = estimated_total - elapsed
        else:
            remaining = 0
        
        print(f"è¿›åº¦: {self.completed}/{self.total} ({percentage:.1f}%) "
              f"æˆåŠŸ: {self.success_count} å¤±è´¥: {self.failure_count} "
              f"å‰©ä½™: {self.format_time(remaining)}")
```

### 2. è¯¦ç»†æŠ¥å‘Šç”Ÿæˆ

```python
async def generate_batch_report(export_results: dict, config: dict) -> str:
    """ç”Ÿæˆæ‰¹é‡å¯¼å‡ºè¯¦ç»†æŠ¥å‘Š"""
    
    report = {
        'export_session': {
            'start_time': config.get('start_time'),
            'end_time': datetime.now().isoformat(),
            'duration': config.get('duration'),
            'total_books': len(export_results)
        },
        'statistics': {
            'successful_exports': sum(1 for r in export_results.values() if r['status'] == 'success'),
            'failed_exports': sum(1 for r in export_results.values() if r['status'] == 'failed'),
            'success_rate': 0,
            'total_file_size': 0
        },
        'books': export_results
    }
    
    # è®¡ç®—æˆåŠŸç‡
    total = report['statistics']['successful_exports'] + report['statistics']['failed_exports']
    if total > 0:
        report['statistics']['success_rate'] = (
            report['statistics']['successful_exports'] / total * 100
        )
    
    # è®¡ç®—æ€»æ–‡ä»¶å¤§å°
    for book_result in export_results.values():
        if book_result['status'] == 'success':
            report['statistics']['total_file_size'] += book_result.get('file_size', 0)
    
    # æ ¼å¼åŒ–æŠ¥å‘Š
    report_str = format_report(report)
    
    # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
    report_file = f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    return report_file
```

## æœ€ä½³å®è·µ

### 1. æ‰¹é‡å¤§å°é€‰æ‹©

- **å°æ‰¹é‡**ï¼ˆ1-10æœ¬ä¹¦ï¼‰ï¼šé€‚åˆç½‘ç»œä¸ç¨³å®šæˆ–éœ€è¦å®æ—¶ç›‘æ§çš„æƒ…å†µ
- **ä¸­æ‰¹é‡**ï¼ˆ10-50æœ¬ä¹¦ï¼‰ï¼šå¹³è¡¡æ•ˆç‡å’Œç¨³å®šæ€§
- **å¤§æ‰¹é‡**ï¼ˆ50+æœ¬ä¹¦ï¼‰ï¼šéœ€è¦è‰¯å¥½çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

### 2. æ—¶é—´å®‰æ’

- **é¿å¼€é«˜å³°æ—¶æ®µ**ï¼šé€‰æ‹©ç½‘ç»œä½¿ç”¨è¾ƒå°‘çš„æ—¶æ®µè¿›è¡Œæ‰¹é‡å¯¼å‡º
- **åˆ†æ—¶æ®µå¤„ç†**ï¼šå°†å¤§æ‰¹é‡ä»»åŠ¡åˆ†æˆå¤šä¸ªæ—¶æ®µå¤„ç†
- **å¤œé—´å¤„ç†**ï¼šåˆ©ç”¨å¤œé—´ç©ºé—²æ—¶é—´è¿›è¡Œæ‰¹é‡å¯¼å‡º

### 3. é”™è¯¯å¤„ç†ç­–ç•¥

- **ç«‹å³é‡è¯•**ï¼šå¯¹äºä¸´æ—¶æ€§é”™è¯¯
- **å»¶è¿Ÿé‡è¯•**ï¼šå¯¹äºæœåŠ¡å™¨é™åˆ¶æˆ–ç½‘ç»œé—®é¢˜
- **è·³è¿‡å¤„ç†**ï¼šå¯¹äºæ— æ³•è§£å†³çš„é”™è¯¯
- **è®°å½•æ—¥å¿—**ï¼šè¯¦ç»†è®°å½•æ‰€æœ‰é”™è¯¯ä¿¡æ¯

---

**æ‰¹é‡å¤„ç†æŒ‡å—åˆ°æ­¤ç»“æŸã€‚** è¿™äº›æ–¹æ³•å’Œç­–ç•¥å°†å¸®åŠ©æ‚¨é«˜æ•ˆåœ°å¤„ç†å¤§é‡ä¹¦ç±å¯¼å‡ºä»»åŠ¡ã€‚ç»§ç»­é˜…è¯»å…¶ä»–æ–‡æ¡£äº†è§£æ›´å¤šåŠŸèƒ½ï¼ ğŸ“š